{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "\n",
    "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 Complete [00h 00m 58s]\n",
      "val_accuracy: 0.8686000108718872\n",
      "\n",
      "Best val_accuracy So Far: 0.8801000118255615\n",
      "Total elapsed time: 00h 09m 33s\n",
      "\n",
      "Search: Running Trial #28\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "384               |384               |units\n",
      "0.0001            |0.001             |learning_rate\n",
      "10                |10                |tuner/epochs\n",
      "0                 |4                 |tuner/initial_epoch\n",
      "0                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6134 - accuracy: 0.7992 - val_loss: 0.4872 - val_accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4376 - accuracy: 0.8492 - val_loss: 0.4592 - val_accuracy: 0.8402\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3964 - accuracy: 0.8632 - val_loss: 0.4236 - val_accuracy: 0.8496\n",
      "Epoch 4/10\n",
      "1703/1875 [==========================>...] - ETA: 0s - loss: 0.3706 - accuracy: 0.8705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(img_train, label_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (img_test, label_test), callbacks \u001b[39m=\u001b[39;49m [ClearTrainingOutput()])\n\u001b[0;32m      3\u001b[0m \u001b[39m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m      4\u001b[0m best_hps \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py:384\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    383\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Hyperband, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:725\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \n\u001b[0;32m    718\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 725\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[0;32m    726\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\OpenSource\\Python\\envs\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:524\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    523\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    525\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    526\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    527\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_hps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(best_hps)\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mfit(img_train, label_train, epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, validation_data \u001b[39m=\u001b[39m (img_test, label_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_hps' is not defined"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc407bb2b50143e22709a3cda124c29410e738a588b4fcd4beb748f4da074135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
